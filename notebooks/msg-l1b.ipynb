{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1c0671-e33a-46dc-ae67-6c28b5949073",
   "metadata": {},
   "source": [
    "# Test reading zipped MSG files and randomly sampling patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e9096-7c81-4dd5-8974-7ae1ba611533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tempfile\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from satpy import Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09073c68-417b-416f-b588-1401a11455cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seviri_path = pathlib.Path(\"/gws/nopw/j04/eo_shared_data_vol2/satellite/seviri/FDS/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04af61f-df75-40e5-aec2-7f50ea182007",
   "metadata": {},
   "outputs": [],
   "source": [
    "(seviri_path/\"2010\"/\"07\"/\"01\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadc593-c6ea-4a3f-9283-2a81c25539f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seviri_files = sorted(list((seviri_path/\"2010\"/\"07\"/\"01\").glob(\"MSG*-NA.zip\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd5365-81bf-45fd-a610-2f112ff20209",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile(seviri_files[48])\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    zf.extractall(tempdir)\n",
    "    print(tempdir)\n",
    "    seviri_file = list(pathlib.Path(tempdir).glob(\"MSG*-NA.nat\"))[0]\n",
    "    print(seviri_file)\n",
    "    scn = Scene([seviri_file], reader=\"seviri_l1b_native\")\n",
    "    scn.load([\n",
    "        'IR_016',\n",
    "        'IR_039',\n",
    "        'IR_087',\n",
    "        'IR_097',\n",
    "        'IR_108',\n",
    "        'IR_120',\n",
    "        'IR_134',\n",
    "        'VIS006',\n",
    "        'VIS008',\n",
    "        'WV_062',\n",
    "        'WV_073'\n",
    "    ])\n",
    "    msg_ds = scn.to_xarray().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9578c1-8d70-4166-a41f-a14143a9e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zipped_msg(filename, channels=None):\n",
    "    if channels is None:\n",
    "        channels = [\n",
    "            'IR_016',\n",
    "            'IR_039',\n",
    "            'IR_087',\n",
    "            'IR_097',\n",
    "            'IR_108',\n",
    "            'IR_120',\n",
    "            'IR_134',\n",
    "            'VIS006',\n",
    "            'VIS008',\n",
    "            'WV_062',\n",
    "            'WV_073'\n",
    "        ]\n",
    "    \n",
    "    zf = zipfile.ZipFile(filename)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        zf.extractall(tempdir)\n",
    "        seviri_file = list(pathlib.Path(tempdir).glob(\"MSG*-NA.nat\"))[0]\n",
    "        scn = Scene([seviri_file], reader=\"seviri_l1b_native\")\n",
    "        scn.load(channels)\n",
    "        msg_ds = scn.to_xarray().load()\n",
    "\n",
    "    return msg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423facfd-6076-492a-8276-61f3eedc17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ds = read_zipped_msg(seviri_files[1], channels=[\n",
    "            'IR_016',\n",
    "            'IR_039',\n",
    "            'IR_087',\n",
    "            'IR_097',\n",
    "            'IR_108',\n",
    "            'IR_120',\n",
    "            'IR_134',\n",
    "            'VIS006',\n",
    "            'VIS008',\n",
    "            'WV_062',\n",
    "            'WV_073'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639d799-4a04-4445-b27c-e7a5df26f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ds.VIS006.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f0869",
   "metadata": {},
   "source": [
    "### Randomly sample 50000 files from the MSG archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce61948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    Generate a random datetime between two datetime objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    random_days = np.random.randint(0, delta.days + 1)\n",
    "    return start + timedelta(days=random_days)\n",
    "\n",
    "def random_time(start, end):\n",
    "    \"\"\"\n",
    "    Generate a random time between two time objects.\n",
    "    \"\"\"\n",
    "    start_minutes = (start.hour * 60) + (start.minute)\n",
    "    end_minutes = (end.hour * 60) + (end.minute)\n",
    "    random_minutes = np.random.randint(start_minutes, end_minutes + 1)\n",
    "    return datetime(2000, 1, 1, random_minutes // 60, random_minutes % 60, 0)\n",
    "\n",
    "def random_datetime(start, end):\n",
    "    \"\"\"\n",
    "    Generate a random datetime between two datetime objects.\n",
    "    \"\"\"\n",
    "    random_date_value = random_date(start, end)\n",
    "    random_time_value = random_time(datetime(2000, 1, 1, 0, 0, 0), datetime(2000, 1, 1, 23, 59, 00))\n",
    "    return datetime(random_date_value.year, random_date_value.month, random_date_value.day,\n",
    "                    random_time_value.hour, random_time_value.minute, random_time_value.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = random_datetime(datetime(2010, 1, 1), datetime(2010, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '/gws/nopw/j04/eo_shared_data_vol2/satellite/seviri/FDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1452471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_msg_files(start, end, num_files=10):\n",
    "    \"\"\"\n",
    "    Sample random MSG files from within the specified date range.\n",
    "    Compile a dataframe with the samples filenames.\n",
    "    Args:\n",
    "        start (datetime): Start date for sampling.\n",
    "        end (datetime): End date for sampling.\n",
    "        num_files (int): Number of files to sample.\n",
    "    \"\"\"\n",
    "\n",
    "    sampled_files = []\n",
    "\n",
    "    # add progress bar\n",
    "    pbar = tqdm(total=num_files, desc=\"Sampling MSG files\", unit=\"file\")\n",
    "    pbar.set_postfix(start=start, end=end)\n",
    "    pbar.update(0)\n",
    "    while len(sampled_files) < num_files:\n",
    "        try:\n",
    "            dt = random_datetime(start, end)\n",
    "            year = dt.year\n",
    "            month = dt.month\n",
    "            day = dt.day\n",
    "            hour = dt.hour\n",
    "\n",
    "            # list all files available for this date and hour\n",
    "            seviri_files = os.listdir(f'{FILEPATH}/{year}/{month:02d}/{day:02d}/')\n",
    "\n",
    "            hour_files = [f for f in seviri_files if f'NA-{year}{month:02d}{day:02d}{hour:02d}' in f]\n",
    "            \n",
    "            if not hour_files:\n",
    "                continue  # Skip if no files found for this datetime\n",
    "            \n",
    "            sampled_file = np.random.choice(hour_files)\n",
    "            sampled_files.append({\n",
    "                'filename': str(sampled_file),\n",
    "                'path': f'{FILEPATH}/{year}/{month:02d}/{day:02d}/{sampled_file}',\n",
    "                'datetime': dt,\n",
    "            })\n",
    "            pbar.update(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # turn the list of sampled files into a DataFrame\n",
    "    df = pd.DataFrame(sampled_files)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    pbar.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8394a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sample_msg_files(datetime(2004, 1, 19), datetime(2025, 2, 28), num_files=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bf511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('msg-sample-50000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('msg-sample-50000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092757b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(str(pathlib.Path().resolve().parent))\n",
    "\n",
    "from scripts.process_utils import CenterWeightedCropDatasetEditor, read_zipped_msg\n",
    "\n",
    "def load_and_patch_msg(file_path, patch_size, fov_radius):\n",
    "    \"\"\"\n",
    "    Load and patch MSG file using Satpy.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the MSG file.\n",
    "        patch_size (int): Size of the patch to crop from the dataset.\n",
    "        fov_radius (float): Field of view radius for cropping.\n",
    "    \n",
    "    Returns:\n",
    "        xarray.Dataset: Patched dataset.\n",
    "    \"\"\"\n",
    "    ds = read_zipped_msg(file_path)\n",
    "\n",
    "    # Crop dataset into patch\n",
    "    crop = CenterWeightedCropDatasetEditor(\n",
    "        patch_shape=(patch_size, patch_size), \n",
    "        fov_radius=fov_radius,\n",
    "        satellite = 'msg')\n",
    "    \n",
    "    result = crop(ds)\n",
    "\n",
    "    if result is None: # i.e. if no valid patch was found\n",
    "        print(f\"Could not find valid patch ...\")\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(0, len(df))\n",
    "test_path = df['path'].iloc[num]\n",
    "test_patch, xmin, ymin = load_and_patch_msg(test_path, patch_size=1024, fov_radius=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patch.IR_016.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a2528",
   "metadata": {},
   "source": [
    "#### Testing how to reduce the file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a5144cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\n",
    "            'IR_016',\n",
    "            'IR_039',\n",
    "            'IR_087',\n",
    "            'IR_097',\n",
    "            'IR_108',\n",
    "            'IR_120',\n",
    "            'IR_134',\n",
    "            'VIS006',\n",
    "            'VIS008',\n",
    "            'WV_062',\n",
    "            'WV_073'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8916f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/users/annaju/eo-data-prep/20160414131241_patch_478_355.nc'\n",
    "test_ds = xr.open_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6733bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.drop_vars([f\"{channel}_acq_time\" for channel in channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d15c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in test_ds.coords:\n",
    "    test_ds[coord] = test_ds[coord].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0bcf37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.to_netcdf(f\"after_basic_changes.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5df2748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {}\n",
    "\n",
    "# Add data variables\n",
    "for var in test_ds.data_vars:\n",
    "    if test_ds[var].dtype in ['float64', 'float32']:\n",
    "        encoding[var] = {\n",
    "            'dtype': 'float32', \n",
    "            'zlib': True, \n",
    "            'complevel': 9, \n",
    "            'shuffle': True,\n",
    "            }\n",
    "\n",
    "# Add coordinates\n",
    "for coord in test_ds.coords:\n",
    "    if test_ds[coord].dtype in ['float64', 'float32']:\n",
    "        encoding[coord] = {\n",
    "            'dtype': 'float32', \n",
    "            'zlib': True, \n",
    "            'complevel': 9, \n",
    "            'shuffle': True,\n",
    "            }\n",
    "\n",
    "test_ds.to_netcdf(\"after_max_compression.nc\", encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7cc98888",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"after_max_compression.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446e2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasmin-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
